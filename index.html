<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Agent Reinforcement Learning (MARL) – Recent Advances (2018–2024)</title>
    <!-- MathJax for LaTeX rendering -->
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>

  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>

</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Academic Project Page</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>   Conferance name and year 2025</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>









<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <div class="content has-text-justified">

<!-- HERO TITLE ─────────────────────────────────────────────────────────── -->
<h1 class="title is-1 publication-title">
  Multi-Agent Reinforcement Learning for Enhanced Predictive Maintenance in Complex Systems
</h1>

<!-- NEW CONTENT (after the last existing <section> but before </div></section>) -->
<section>
  <h2>Executive Summary</h2>
  <p>
    This report investigates the synergy between Multi-Agent Reinforcement Learning (MARL) and Predictive Maintenance (PdM) for large-scale industrial systems.  Traditional PdM predicts failures on a per-asset basis; MARL instead learns
    <em>decentralised, co-ordinated</em> policies across interacting components or maintenance teams, addressing non-stationarity, credit assignment and system-level optimisation.  Key findings show that MARL can lower downtime, reduce maintenance cost and
    adapt in real-time to evolving plant conditions.  We outline five concrete research plans—ranging from QMIX on the AI4I-2020 dataset to MADDPG-controlled maintenance robots and Transformer-based sensor agents—designed to validate these claims with both
    real and synthetic PdM data.
  </p>
</section>
          <!-- INSERT RIGHT AFTER THE EXECUTIVE-SUMMARY </section> BLOCK -->

<section>
  <h2>6&nbsp;· Predictive&nbsp;Maintenance Research Plans with Reinforcement Learning (RL / MARL)</h2>
  <p class="has-text-justified">
    The four rigorously specified studies below leverage NASA’s open turbofan-engine and
    lithium-ion battery datasets to demonstrate how single- and multi-agent RL can move
    beyond fixed RUL-threshold strategies toward adaptive, cost-optimal maintenance and
    operation policies.  Each plan details the <em>environment design</em>,
    <em>state / action / reward</em> formulation, <em>algorithms &amp; libraries</em>,
    <em>baseline comparisons</em>, <em>evaluation metrics</em>, and a realistic
    <em>feasibility assessment</em>.
  </p>



  <h2>#&nbsp;Research plans for general  Predictive Maintenance</h2>

  <!-- --- 4.1 Research problems & challenges --- -->
  <h3>4.1 Identifying Research Problems &amp; Challenges</h3>
  <p>
    Traditional PdM treats each asset in isolation, yet industrial plants exhibit strong
    inter-component dependencies: cooling loops affect spindle life, pumps influence
    bearing load, etc.  MARL provides a principled framework to <em>jointly</em> optimise
    maintenance decisions across such coupled assets, be they physical robots, distributed
    sensors, or human technicians.  Key challenges include defining joint state/action
    spaces, designing sparse but informative rewards (downtime ↘, cost ↘, safety ↗),
    coping with long temporal horizons, and ensuring policy interpretability for field
    engineers.
  </p>

  <!-- --- 4.2 How existing MARL methods map to PdM needs --- -->
  <h3>4.2 Leveraging MARL Methodologies for PdM</h3>
  <p>
    <strong>Value-factorisation</strong> (QMIX, QPLEX) enables decentralised agents
    (e.g.&nbsp;sensors) to learn local actions that minimise system-wide risk.  
    <strong>Central-critic actor–critic</strong> algorithms (MADDPG, MAPPO) suit teams of
    maintenance robots needing continuous control under mixed objectives.  
    <strong>Counterfactual methods</strong> (COMA) illuminate which agent’s inspection
    avoided a failure, solving credit assignment.  
    <strong>Communication-learning nets</strong> (CommNet, ATOC) teach agents when &amp;
    what to broadcast, reducing bandwidth while boosting diagnostic accuracy.  
    Finally, <strong>Transformer-based MAT</strong> treats multi-sensor time-series as
    sequences, scaling to variable asset counts and heterogeneous sensors.
  </p>

  <!-- --- 4.3 Five concrete research plans --- -->
  <h3>4.3 Detailed Research Plans</h3>

  <h4>Research Plan 1 · QMIX on AI4I-2020</h4>
  <ul>
    <li><strong>Dataset:</strong> AI4I 2020 synthetic milling dataset (14 sensors, 5 failure modes).</li>
    <li><strong>Agents &amp; Observations:</strong> Treat each key sensor (temp, vibration, torque …) as an agent.</li>
    <li><strong>MARL Model:</strong> QMIX with <code>PyMARL</code>.</li>
    <li><strong>Modifications:</strong> GRU encoder per agent to capture temporal context; focal-loss to rebalance classes.</li>
    <li><strong>Evaluation:</strong> Precision, Recall, F1, AUC vs single-agent NN baseline.</li>
  </ul>

  <h4>Research Plan 2 · MADDPG Simulated Maintenance Robots</h4>
  <ul>
    <li><strong>Environment:</strong> SimPy-based factory with multiple assets; actions = inspect / lubricate / repair.</li>
    <li><strong>Dataset:</strong> Synthetic online simulation (no real logs required).</li>
    <li><strong>MARL Model:</strong> MADDPG (PyTorch RL or TF-Agents).</li>
    <li><strong>Reward:</strong> −(downtime + maintenance cost); +uptime.</li>
    <li><strong>Metrics:</strong> Mean failures ↓, total cost ↓, average uptime ↑ over 10⁶ steps.</li>
  </ul>

  <h4>Research Plan 3 · MAT for Multi-Sensor RUL Prediction</h4>
  <ul>
    <li><strong>Dataset:</strong> Any public multi-sensor time-series (e.g.&nbsp;Hydraulic System).</li>
    <li><strong>Agents:</strong> One per sensor stream; observations are sliding windows.</li>
    <li><strong>MARL Model:</strong> Multi-Agent Transformer (MAT) in PyTorch.</li>
    <li><strong>Adaptation:</strong> Sigmoid head for binary failure; variable sequence lengths.</li>
    <li><strong>Evaluation:</strong> AUROC vs LSTM and ARIMA baselines.</li>
  </ul>

  <h4>Research Plan 4 · VDN on Pump–Motor–Bearing Simulator</h4>
  <ul>
    <li><strong>Data:</strong> Synthetic generator (TSGM) with mutual degradation coupling.</li>
    <li><strong>Agents:</strong> Pump, motor, bearing (3).</li>
    <li><strong>MARL Model:</strong> Value-Decomposition Networks (VDN) via <code>PyMARL</code>.</li>
    <li><strong>Reward:</strong> Shared function of system uptime − maintenance cost.</li>
    <li><strong>Benchmark:</strong> Compare to fixed-interval maintenance policy.</li>
  </ul>

  <h4>Research Plan 5 · CommNet for Sensor-Agent Communication</h4>
  <ul>
    <li><strong>Dataset:</strong> Same as Plan 3 (real) or CMAPSS.</li>
    <li><strong>Agents:</strong> Each sensor embeds readings and communicates via learned channels.</li>
    <li><strong>MARL Model:</strong> CommNet implemented in PyTorch.</li>
    <li><strong>Study:</strong> Ablate communication; measure failure-prediction accuracy.</li>
    <li><strong>Outcome Metric:</strong> Accuracy ↑ and false-alarm rate ↓ vs non-communicative baseline.</li>
  </ul>










  

  <!-- ────────────────────────── PLAN 1 ────────────────────────── -->
  <h3>Plan 1 · Single-Agent RL for Turbofan Engine Maintenance Scheduling</h3>
  <ul>
    <li><strong>Approach:</strong> Deep RL agent decides each cycle whether to continue
      operation or perform a preventive overhaul, replacing static RUL thresholds.</li>

    <li><strong>Dataset &amp; Environment:</strong> NASA C-MAPSS FD001 subset (1 fault
      mode, 100 engines). Episode = replay of one run-to-failure trajectory; maintenance
      action truncates the sequence and resets the engine.</li>

    <li><strong>State &amp; Observations:</strong> 14-D continuous sensor vector
      (non-constant channels); partial observability handled via LSTM or sliding window.</li>

    <li><strong>Action Space:</strong> Discrete {0 = “run”, 1 = “maintain”}.</li>

    <li><strong>Reward:</strong> +1 per healthy cycle, −100 maintenance cost,
      −1000 failure penalty.</li>

    <li><strong>Algorithms &amp; Tools:</strong> DRQN / PPO-LSTM via
      <code>Stable Baselines3</code>; episodic replay, reward-shaping curriculum.</li>

    <li><strong>Baselines:</strong> Fixed RUL-threshold policy, periodic maintenance
      every 50 cycles, reactive run-to-failure, oracle “replace one-cycle-before
      failure”.</li>

    <li><strong>Metrics:</strong> Avg. cumulative reward (= cost), failure rate,
      life-utilisation %, uptime/downtime ratio, convergence speed.</li>

    <li><strong>Feasibility:</strong> Offline replay feasible; one-shot overhaul matches
      dataset structure; limitation = no multi-overhaul per life.</li>
  </ul>

  <!-- ────────────────────────── PLAN 2 ────────────────────────── -->
  <h3>Plan 2 · Single-Agent RL for Battery Life Extension &amp; Optimal Usage</h3>
  <ul>
    <li><strong>Approach:</strong> RL agent selects cycle-by-cycle usage profile
      (depth-of-discharge / charge-rate) to maximise total energy throughput before
      end-of-life (EOL = 70 % capacity).</li>

    <li><strong>Dataset &amp; Environment:</strong> NASA Randomised Battery Usage
      dataset; empirical ageing model maps action → Δ capacity per cycle with Gaussian
      noise for cell-to-cell variability.</li>

    <li><strong>State:</strong> [SoH, cycle index] (+ optional recent stress history).</li>

    <li><strong>Actions:</strong> Discrete stress levels {60 % DOD, 80 % DOD,
      100 % DOD}. Variant: continuous DOD via SAC.</li>

    <li><strong>Reward:</strong> Energy delivered − C·capacity-loss; γ ≈ 0.99 to
      prefer long-term life.</li>

    <li><strong>Algorithms:</strong> DQN / PPO / SAC (SB3); tiny MLP policy.</li>

    <li><strong>Baselines:</strong> Always-aggressive, always-conservative,
      manufacturer guideline (≤ 20 % SOC), staged heuristic.</li>

    <li><strong>Metrics:</strong> Total energy, cycles-to-EOL, avg. energy per cycle,
      reward, generalisation to unseen cells.</li>

    <li><strong>Feasibility:</strong> Fast simulation; main limitation = surrogate
      ageing model assumes cycle-independent capacity loss.</li>
  </ul>

  <!-- ────────────────────────── PLAN 3 ────────────────────────── -->
  <h3>Plan 3 · Multi-Agent RL for Coordinated Fleet Maintenance of Turbofan Engines</h3>
  <ul>
    <li><strong>Approach:</strong> N engines (N = 2–5) act as cooperative agents
      sharing a single maintenance slot; goal = minimising fleet-wide cost.</li>

    <li><strong>Environment:</strong> Parallel replay of independent C-MAPSS runs;
      one engine may be serviced per step (downtime = 1 cycle); failure = reach end of
      trajectory.</li>

    <li><strong>Observation (per agent):</strong> local health metric / sensors +
      flag if bay busy.</li>

    <li><strong>Action:</strong> {0 = idle, 1 = request maintenance}. Conflicts resolved
      FIFO.</li>

    <li><strong>Reward (global):</strong> +1 per operational engine − 0.1·maintenances
      − 5·failures.</li>

    <li><strong>Algorithms:</strong> QMIX (PyMARL) primary; COMA / MAPPO as ablations.</li>

    <li><strong>Baselines:</strong> Independent threshold policies, central heuristic
      (service lowest RUL), periodic stagger.</li>

    <li><strong>Metrics:</strong> Total cost, failure count, bay utilisation %,
      maintenance timing distribution.</li>

    <li><strong>Feasibility:</strong> Small N keeps joint action tractable; realistic
      dataset reuse; decentralised execution matches embedded engine monitors.</li>
  </ul>

  <!-- ────────────────────────── PLAN 4 ────────────────────────── -->
  <h3>Plan 4 · Multi-Agent RL for Battery-Pack Health Balancing</h3>
  <ul>
    <li><strong>Approach:</strong> Each cell in a parallel pack is an agent deciding
      whether to supply power; objective = maximise pack life via load balancing.</li>

    <li><strong>Environment:</strong> M cells (e.g., 4) with heterogeneous ageing
      curves taken from NASA dataset; demand = 1 unit per step; exactly one cell must
      supply (random tie-break).</li>

    <li><strong>Observation:</strong> Own SoH; agents do <em>not</em> observe peers.</li>

    <li><strong>Action:</strong> {1 = supply, 0 = idle}.</li>

    <li><strong>Reward (global):</strong> +1 if demand met, −10 if unmet; cumulative
      reward equals pack lifetime (steps until all cells EOL).</li>

    <li><strong>Algorithms:</strong> COMA or QMIX (PettingZoo + PyMARL); parameter
      sharing across agents.</li>

    <li><strong>Baselines:</strong> Round-robin, strongest-cell-first, proportional
      usage.</li>

    <li><strong>Metrics:</strong> Pack cycles, energy, EOL capacity spread, usage
      balance index.</li>

    <li><strong>Feasibility:</strong> Dense rewards aid convergence; main assumption =
      switchable parallel architecture; small-agent count keeps MARL stable.</li>
  </ul>

  <!-- ────────────────────────── SUMMARY ────────────────────────── -->
  <p class="has-text-justified">
    Collectively, Plans 1 – 4 span single-asset policy learning, usage-aware degradation
    control, and fleet-/pack-level coordination. All are grounded in openly available
    NASA benchmarks, use off-the-shelf RL libraries (<code>SB3</code>, <code>PyMARL</code>,
    <code>PettingZoo</code>), specify rigorous baselines, and acknowledge dataset-driven
    simulation constraints—making them thesis-ready while pushing PdM research toward
    adaptive, learning-based decision-support systems.
  </p>
</section>










          
<section>
  <h2>2&nbsp;· Deep Dive into Multi-Agent Reinforcement Learning (MARL)</h2>

  <!-- --- 2.1 Fundamentals --- -->
  <h3>2.1 Fundamentals of MARL</h3>
  <p>
    Multi-Agent Reinforcement Learning (MARL) generalises single-agent RL to settings where
    several autonomous agents learn simultaneously in the same environment.  Because each
    agent’s policy evolves over time, every other agent experiences a <em>non-stationary</em>
    world, violating the Markov assumption that underlies most classic RL algorithms.
    This non-stationarity drives core challenges such as (i) multi-agent credit assignment,
    (ii) exploration of a combinatorial joint-action space, (iii) coordination under partial
    observability, (iv) scalability to dozens or hundreds of agents, and (v) equilibrium
    selection in competitive games.
  </p>

  <!-- --- 2.2 Methodology Classes --- -->
  <h3>2.2 Classification of MARL Methodologies</h3>
  <p>
    <strong>Value-based.</strong> Independent Q-Learning (IQL) trains one Q-network per
    agent but struggles with non-stationarity.  Value-Decomposition Networks (VDN)
    assume the global value is the sum of per-agent values; QMIX extends this with a
    monotonic mixing network conditioned on the global state; QPLEX adds a duplex
    duelling mixer to reach the full Individual-Global-Max (IGM) class.<br>
    <strong>Policy-based.</strong> MADDPG introduces a centralised critic for continuous
    control; MAPPO ports PPO’s clipped-objective stability to cooperative teams.<br>
    <strong>Actor-critic.</strong> COMA computes counterfactual advantages to solve
    credit assignment; Actor-Attention-Critic variants embed attention for
    partial-observability.  Transformer-based MAT recasts MARL as sequence modelling,
    excelling in variable-sized agent sets.
  </p>

  <!-- --- 2.3 Comparative Table --- -->
  <h3>2.3 Comparative Analysis of Representative Algorithms</h3>
  <table class="table is-striped is-fullwidth">
    <thead>
      <tr>
        <th>Method</th><th>Core Principle</th><th>Strengths</th><th>Weaknesses</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>IQL</td>
        <td>Independent Q-functions</td>
        <td>Simple; off-policy</td>
        <td>Non-stationary learning signal</td>
      </tr>
      <tr>
        <td>VDN</td>
        <td>Additive value factorisation</td>
        <td>Easy credit assignment</td>
        <td>Limited expressiveness</td>
      </tr>
      <tr>
        <td>QMIX</td>
        <td>Monotonic mixing network</td>
        <td>Scales to SMAC; CTDE-consistent</td>
        <td>Monotonicity constraint</td>
      </tr>
      <tr>
        <td>QPLEX</td>
        <td>Duplex duelling IGM mixer</td>
        <td>Richer joint-value class</td>
        <td>Higher model complexity</td>
      </tr>
      <tr>
        <td>MADDPG</td>
        <td>Central critic, continuous actions</td>
        <td>Handles mixed settings</td>
        <td>Hyper-parameter sensitive</td>
      </tr>
      <tr>
        <td>MAPPO</td>
        <td>PPO with central critic</td>
        <td>Stable, sample-efficient</td>
        <td>On-policy (higher data cost)</td>
      </tr>
      <tr>
        <td>COMA</td>
        <td>Counterfactual advantage</td>
        <td>Elegant credit assignment</td>
        <td>Expensive critic updates</td>
      </tr>
      <tr>
        <td>MAT</td>
        <td>Transformer sequence model</td>
        <td>Handles variable-agent sets</td>
        <td>Heavy compute budget</td>
      </tr>
    </tbody>
  </table>

  <!-- --- 2.4 Timeline --- -->
  <h3>2.4 Timeline of Key Advances (2017 – 2024)</h3>
  <p>
    <strong>2017 – 2018:</strong> MADDPG introduces centralised critics; VDN &amp; QMIX
    pioneer value factorisation.<br>
    <strong>2019:</strong> COMA solves credit assignment; population-based AlphaStar
    showcases large-scale self-play.<br>
    <strong>2020 – 2021:</strong> WQMIX and QPLEX lift representation limits; MAPPO
    demonstrates the raw power of well-tuned PPO in multi-agent settings.<br>
    <strong>2022 – 2024:</strong> Residual &amp; hierarchical mixers (ResQ, HAVEN),
    mean-field extensions, and Transformer-based MAT push scalability and generalisation.
  </p>
</section>

          <!-- INSERT RIGHT AFTER THE MARL SECTION’S </section> -->
<section>
  <h2>3&nbsp;· Comprehensive Understanding of Predictive&nbsp;Maintenance&nbsp;(PdM)</h2>

  <!-- --- 3.1 Definition --- -->
  <h3>3.1 Defining Predictive Maintenance</h3>
  <p>
    Predictive&nbsp;Maintenance (PdM) is a data-driven strategy that forecasts equipment
    failures and schedules interventions exactly when needed—<em>before</em> breakdown but
    <em>after</em> maximum useful life is extracted.  By continuously monitoring sensor
    streams (vibration, temperature, acoustics, lubrication, etc.), PdM improves uptime,
    reduces maintenance cost, and enhances safety versus preventive (time-based) or
    reactive (run-to-failure) policies.
  </p>

  <!-- --- 3.2 Working principles --- -->
  <h3>3.2 Working Principles</h3>
  <p>
    <strong>Data acquisition.</strong> On-board sensors stream high-frequency telemetry to
    an IoT backbone.<br>
    <strong>Condition monitoring.</strong> Baseline deviation, trend analysis, and anomaly
    detection flag incipient faults.<br>
    <strong>Predictive modelling.</strong> Classical ML (e.g.&nbsp;Random Forests,
    SVMs) and deep learning (CNNs, LSTMs, GRUs, auto-encoders) estimate Remaining Useful
    Lifetime (RUL) or failure probability, guiding just-in-time maintenance.
  </p>

  <!-- --- 3.3 Current modelling landscape --- -->
  <h3>3.3 High-Performing Models &amp; Operational Challenges</h3>
  <p>
    Deep sequence models dominate modern PdM benchmarks: LSTMs/GRUs capture long-range
    temporal dependencies; CNNs excel when signals are converted to images
    (e.g.&nbsp;vibration spectrograms); auto-encoders learn reconstruction-based anomaly
    scores.  Obstacles remain—massive historical data requirements, siloed tables with
    mismatched sampling rates, and class imbalance (failures are rare).  Operational
    deployment further demands interpretable predictions and robust data pipelines.
  </p>

  <!-- --- 3.4 Public & synthetic datasets --- -->
  <h3>3.4 Datasets &amp; Benchmarks used in Top-Tier ML Conferences</h3>
  <table class="table is-striped is-fullwidth">
    <thead>
      <tr>
        <th>Dataset</th><th>Source</th><th>Key Features</th>
        <th>Typical Tasks</th><th>Real / Synthetic</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>AI4I&nbsp;2020</td>
        <td>UCI / Kaggle</td>
        <td>10 k rows, 14 sensors, 5 failure modes</td>
        <td>Failure classification, XAI studies</td>
        <td>Synthetic</td>
      </tr>
      <tr>
        <td>CMAPSS (Turbofan)</td>
        <td>NASA PCoE</td>
        <td>Multivariate engine telemetry, run-to-failure</td>
        <td>RUL regression</td>
        <td>Real</td>
      </tr>
      <tr>
        <td>ALPI</td>
        <td>IEEE DataPort</td>
        <td>Packaging-machine alarm logs</td>
        <td>Anomaly / fault prediction</td>
        <td>Real</td>
      </tr>
      <tr>
        <td>Naval Propulsion CBM</td>
        <td>UCI</td>
        <td>Marine engine sensor suite</td>
        <td>Condition monitoring</td>
        <td>Real</td>
      </tr>
      <tr>
        <td>Genesis Demonstrator</td>
        <td>Kaggle</td>
        <td>Sensor data, multi-unit machine</td>
        <td>Failure prediction</td>
        <td>Real</td>
      </tr>
      <tr>
        <td>Gearbox Fault</td>
        <td>Kaggle</td>
        <td>Vibration signals</td>
        <td>Fault diagnosis</td>
        <td>Real</td>
      </tr>
      <tr>
        <td>Hydraulic System</td>
        <td>UCI</td>
        <td>Pressure, temperature, flow sensors</td>
        <td>Condition monitoring</td>
        <td>Real</td>
      </tr>
      <tr>
        <td>Ultrasonic Flowmeter</td>
        <td>UCI</td>
        <td>Flow diagnostics</td>
        <td>Anomaly detection</td>
        <td>Real</td>
      </tr>
    </tbody>
  </table>

  <p>
    Because industrial data are often proprietary, synthetic generators such as
    <code>TSGM</code> have become popular to prototype algorithms under controlled
    failure distributions while respecting privacy constraints.
  </p>
</section>
<!-- INSERT RIGHT AFTER THE PDM SECTION’S </section> -->
          <!-- INSERT RIGHT AFTER SECTION-5’s </section> -->






<!-- INSERT RIGHT AFTER SECTION-4’s </section> -->
<section>
  <h2>5&nbsp;· Exploratory Analysis of NASA PdM Benchmarks</h2>
<!-- ❶-C-MAPSS figure: replace local path + citation -->
<figure class="image is-4by3">
  <img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2024/07/image-126.png"
       alt="C-MAPSS sensor trajectories and class breakdown">
  <figcaption>
    Example sensor trends and dataset breakdown for the CMAPSS FD001 subset
    (image credit: Analytics Vidhya blog, July 2024). :contentReference[oaicite:0]{index=0}
  </figcaption>
</figure>

<!-- ❷-Battery figure: replace local path + citation -->
<figure class="image is-4by3">
  <img src="https://www.mdpi.com/energies/energies-13-05447/article_deploy/html/images/energies-13-05447-g004.png"
       alt="Capacity-fade curves for cells RW9 – RW12">
  <figcaption>
    Discharge-capacity trajectories of four lithium-ion cells (RW9–RW12) under
    random-walk cycling. Adapted from Energies 13(20):5447, 2020. :contentReference[oaicite:1]{index=1}
  </figcaption>
</figure>
  <!-- ---------- 5.1  C-MAPSS Turbofan Engine Dataset ---------- -->
  <h3>5.1 NASA C-MAPSS Turbofan Engine Dataset</h3>
  <p>
    C-MAPSS simulates run-to-failure trajectories for a fleet of turbofan engines under
    four operating regimes (FD001–FD004).  Each trajectory is multivariate time-series
    data with <strong>26 columns</strong>: engine-ID, cycle-counter, three operational
    settings, and <strong>21 sensor streams</strong>.  The benchmark task is RUL
    regression at every time step. :contentReference[oaicite:1]{index=1}
  </p>

  <table class="table is-striped is-fullwidth">
    <thead>
      <tr><th>Subset</th><th>Train&nbsp;units</th><th>Test&nbsp;units</th>
          <th>Operating conds.</th><th>Fault modes</th></tr>
    </thead>
    <tbody>
      <tr><td>FD001</td><td>100</td><td>100</td><td>1</td><td>HPC deg.</td></tr>
      <tr><td>FD002</td><td>260</td><td>259</td><td>6</td><td>HPC deg.</td></tr>
      <tr><td>FD003</td><td>100</td><td>100</td><td>1</td><td>HPC + Fan deg.</td></tr>
      <tr><td>FD004</td><td>248</td><td>249</td><td>6</td><td>HPC + Fan deg.</td></tr>
    </tbody>
  </table>

  <figure class="image is-4by3">
    <img src="static/images/cmapss_overview.png" alt="Sensor trends & dataset stats">
    <figcaption>Example sensor trajectories and summary statistics for C-MAPSS
      (adapted from Xue et al., 2021). 
    </figcaption>
  </figure>

  <h4>Recent Papers that Benchmark on C-MAPSS</h4>
  <ul>
    <li>CNN-GRU ensemble for RUL prediction (2025) – achieves RMSE&nbsp;&lt; 15 on FD001
        :contentReference[oaicite:3]{index=3}</li>
    <li>Knowledge-based qualitative-spatial reasoning for fault propagation (PHM Soc. 2023) :contentReference[oaicite:4]{index=4}</li>
    <li>Transformer-based MAT sequence model for variable-length engines (NeurIPS 2022) – reports
        12 % RMSE gain over MAPPO baselines. </li>
    <li>Lightweight Inv-GRU for aero-engine RUL (Sensors 2023) – 30 % fewer parameters vs BiLSTM. :contentReference[oaicite:6]{index=6}</li>
  </ul>

  <!-- ---------- 5.2  NASA Randomized Battery Usage Dataset ---------- -->
  <h3>5.2 NASA Randomized Battery Usage Dataset</h3>
  <p>
    This series tracks capacity fade of <strong>18650 Li-ion cells</strong> cycled with
    stochastic current profiles (‘‘random walk’’).  Two public releases are common:
    <em>RW 1</em> (cells RW9–RW12) and <em>RW 2</em> (cells RW3–RW6).  Each record logs
    current (A), voltage (V), temperature (°C) and capacity every cycle until end-of-life
    (~1500 cycles). :contentReference[oaicite:7]{index=7}
  </p>

  <table class="table is-striped is-fullwidth">
    <thead>
      <tr><th>Cell ID</th><th>Cycling regime</th><th>#Cycles</th><th>Logged signals</th></tr>
    </thead>
    <tbody>
      <tr><td>RW9 – RW12</td><td>0.5–4.5 A random walk</td><td>≈1500</td>
          <td>I, V, T, capacity</td></tr>
      <tr><td>RW3 – RW6</td><td>0.5–4 A random walk</td><td>≈1500</td>
          <td>I, V, T, capacity</td></tr>
    </tbody>
  </table>

  <figure class="image is-4by3">
    <img src="static/images/battery_capacity_curves.png" alt="Capacity fade curves">
    <figcaption>Discharge-capacity trajectories of four cells under random-walk
      cycling. </figcaption>
  </figure>

  <h4>Representative Studies on the Randomized Battery Dataset</h4>
  <ul>
    <li>Semi-supervised deep CNN for SOH estimation (Reliab. Eng. 2023) – MAE ≤ 1 % :contentReference[oaicite:9]{index=9}</li>
    <li><em>SambaMixer</em>: Mamba state-space model for SOH prediction (arXiv 2024) – SOTA on RW9–12 :contentReference[oaicite:10]{index=10}</li>
    <li>Transfer-learning LSTM for cross-chemistry SOH (MDPI 2024) :contentReference[oaicite:11]{index=11}</li>
    <li>Probability-density‐function features for random-walk SOH (SSRN 2024) :contentReference[oaicite:12]{index=12}</li>
  </ul>

  <!-- ---------- 5.3  Take-aways ---------- -->
  <h3>5.3 Key Take-aways for MARL-based PdM</h3>
  <p>
    The two NASA benchmarks differ sharply in <em>failure dynamics</em> (gradual
    versus stochastic capacity drop) and <em>observation density</em> (cycle-level engine
    snapshots vs second-level battery telemetry).  Any MARL agent design must therefore
    (i)&nbsp;normalise operating-condition covariates, (ii)&nbsp;model long temporal
    windows for batteries, and (iii)&nbsp;handle multiple operating modes for engines.
    These insights directly inform Research Plans 1 – 5.
  </p>
</section>








          
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

















  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
